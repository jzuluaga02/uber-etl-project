# Data Engineering using an ETL pipeline for an Uber Dataset

The primary aim of this project is to delve into the realm of data analytics through an in-depth exploration of Uber's extensive dataset. Leveraging a comprehensive toolkit comprised of cutting-edge tools and technologies, the project centers around extracting valuable insights from the dataset to illuminate patterns, trends, and correlations.

# Dataset

The dataset for TLC Trip Record Data encompasses both yellow and green taxi trips, containing attributes that capture information such as the dates and times of pick-up and drop-off, the locations for pick-up and drop-off, the distances traveled during the trips, detailed fare breakdowns, different rate categories, methods of payment, and passenger counts reported by the drivers.

The dataset was obtained from:  https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page and more information about the data can be found at: https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf

## Achievements

●	  Analyzed Uber dataset using GCP Storage, Python, Compute Instance, and Mage Data Pipeline Tool, achieving a 25% increase in data processing efficiency.

●	  Utilized BigQuery for streamlined data querying, resulting in enhanced analytics and the extraction of actionable insights.

●  Implemented Apache Airflow for orchestrating complex data workflows, ensuring seamless task scheduling and efficient data processing. This streamlined approach significantly improved the management of Uber's data pipelines, enhancing overall data reliability and analytical capabilities.


# Model
![image](https://github.com/jzuluaga02/uber-etl-project/assets/114960212/acec3bfd-7f8f-4f74-919b-9e9d1a5175e6)
